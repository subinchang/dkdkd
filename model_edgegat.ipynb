{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YcNmCK2Xq3d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(12)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn import EdgeGATConv\n",
    "from dgl import batch\n",
    "import dgl.function as fn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, precision_recall_curve\n",
    "import optuna\n",
    "from optuna import trial\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVDRJUqFVlqr"
   },
   "outputs": [],
   "source": [
    "print(dgl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLlbWBIzVnqD",
    "outputId": "3b897e61-25f3-4cd7-f575-2e774440f847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 30 08:08:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8zujTKwVnsh"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_availabe() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLro_YzPXs_J"
   },
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvX3fOY7Xxji"
   },
   "outputs": [],
   "source": [
    "# Change ./GC to your dataset folder\n",
    "dataset = dgl.data.CSVDataset(./GC)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDwkQ-iaXyp2"
   },
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "\tprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdHOeFItXzri"
   },
   "outputs": [],
   "source": [
    "graph0, data0 = dataset[0]\n",
    "print(graph0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kibH81zfX1Gd"
   },
   "outputs": [],
   "source": [
    "print(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2zHjlGdX3W5"
   },
   "outputs": [],
   "source": [
    "# create self loop for each node\n",
    "self_dataset = []\n",
    "for graph, data in dataset:\n",
    "    graph = dgl.add_self_loop(graph)\n",
    "    self_dataset.append((graph, data))\n",
    "dataset = self_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2n-_K4BX5Zr"
   },
   "outputs": [],
   "source": [
    "# check num_edges to see if self loops are added properly\n",
    "graph0, data0 = dataset[0]\n",
    "print(graph0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_PkrNBUX6op"
   },
   "source": [
    "# 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d1keBGsX-ui"
   },
   "outputs": [],
   "source": [
    "labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "print(f\"{labels}, with {len(labels)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIWFCPZKYAYS"
   },
   "outputs": [],
   "source": [
    "neg_indices = np.where(labels == 0)[0]\n",
    "pos_indices = np.where(labels == 1)[0]\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.6, 0.2, 0.2\n",
    "\n",
    "# divide negative label indices into train / val / test sets\n",
    "train_neg, val_test_neg = train_test_split(neg_indices, train_size=train_ratio, random_state=12)\n",
    "val_neg, test_neg = train_test_split(val_test_neg, train_size=0.5, random_state=12)\n",
    "\n",
    "# divide positive label indices into train / val / test sets\n",
    "train_pos, val_test_pos = train_test_split(pos_indices, train_size=train_ratio, random_state=12)\n",
    "val_pos, test_pos = train_test_split(val_test_pos, train_size=0.5, random_state=12)\n",
    "\n",
    "train_indices = np.concatenate([train_neg, train_pos])\n",
    "val_indices = np.concatenate([val_neg, val_pos])\n",
    "test_indices = np.concatenate([test_neg, test_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzs6DVatYCZL"
   },
   "outputs": [],
   "source": [
    "# divide graphs according to indices divided above\n",
    "train_dataset, val_dataset, test_dataset = [], [], []\n",
    "\n",
    "for index in train_indices:\n",
    "    train_dataset.append(dataset[index])\n",
    "\n",
    "for index in val_indices:\n",
    "    val_dataset.append(dataset[index])\n",
    "\n",
    "for index in test_indices:\n",
    "    test_dataset.append(dataset[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if they are divided well\n",
    "print(f\"Total dataset: {len(dataset)}, \\nTrain:Val:Test = {len(train_dataset)}:{len(val_dataset)}:{len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnBULDl3YGsv"
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "np.random.shuffle(train_dataset)\n",
    "np.random.shuffle(val_dataset)\n",
    "np.random.shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nnoYoeeYJ8h"
   },
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOWC3UWuYMYu"
   },
   "outputs": [],
   "source": [
    "class EdgeGATClassifier(nn.Module):\n",
    "    def __init__(self, in_feats, edge_feats, hidden_feats, out_feats, num_heads):\n",
    "        super(EdgeGATClassifier, self).__init__()\n",
    "        self.conv1 = EdgeGATConv(in_feats, edge_feats, hidden_feats, num_heads)\n",
    "        self.conv2 = EdgeGATConv(hidden_feats, edge_feats, hidden_feats, num_heads)\n",
    "        self.fc = nn.Linear(hidden_feats, 1)\n",
    "    \n",
    "    def forward(self, bg):\n",
    "        h = bg.ndata['feat'] # node features\n",
    "        e = bg.edata['feat'] # edge features\n",
    "        \n",
    "        h = self.conv1(bg, h, e)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = torch.mean(h, dim=1, keepdim=True)\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "\n",
    "        h = self.conv2(bg, h, e)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = torch.mean(h, dim=1, keepdim=True)\n",
    "        \n",
    "        bg.ndata['h'] = h\n",
    "        h = dgl.mean_nodes(bg, 'h')\n",
    "        h = self.fc(h)\n",
    "        h = torch.squeeze(h, dim=-1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1WLqOMMYOLB"
   },
   "source": [
    "# 4. Training with Optuna\n",
    "- Training works to minimize the loss set in the criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-akAeXXJYUHt"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    input_dim = graph0.ndata['feat'].shape[1]\n",
    "    edge_dim = graph0.edata['feat'].shape[1]\n",
    "    num_classes = 1\n",
    "    \n",
    "    hidden_dim = 2 ** trial.suggest_int('hidden_dim', 3, 6)\n",
    "    num_heads = trial.suggest_int('num_heads', 2, 5)\n",
    "    learning_rate = 10 ** trial.susgest_int('learning_rate', -5, -2)\n",
    "    num_epochs = trial.suggest_discrete_uniform('num_epochs', 50, 100, 10)\n",
    "    batch_size = 2 ** trial.suggest_int('batch_size', 5, 8)\n",
    "\n",
    "    # load splitted data\n",
    "    train_dataloader = GraphDataLoader(train_dataset, batch_size=batch_size, drop_last=False)\n",
    "    val_dataloader = GraphDataLoader(val_dataset, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "    # define model\n",
    "    model = EdgeGATClassifier(input_dim, edge_dim, hidden_dim, num_classes, num_heads)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # train mode\n",
    "    model.train()\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        preds = model(batched_graph)\n",
    "        loss = criterion(preds.float(), labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    step = 0\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in val_dataloader:\n",
    "            step += 1\n",
    "            pred = model(batched_graph)\n",
    "            loss = criterion(pred.float(), labels.float())\n",
    "            val_loss += loss.item()\n",
    "            average_val_loss = val_loss / step\n",
    "            trial.report(average_val_loss, step)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "        return average_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF9LX-iCYchR"
   },
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=12)\n",
    "study = optuna.create_study(study_name='EdgeGAT', direction='minimize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EMsaHbsYfHf"
   },
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Esf6S7b1ZF9J"
   },
   "outputs": [],
   "source": [
    "# best loss value\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYkS_ynZYt1g"
   },
   "source": [
    "# 5. With best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGGyDNm1ZHoH"
   },
   "outputs": [],
   "source": [
    "# default\n",
    "input_dim = graph0.ndata['feat'].shape[1]\n",
    "edge_dim = graph0.edata['feat'].shape[1]\n",
    "num_classes = 1\n",
    "\n",
    "# hyperparameters\n",
    "hidden_dim = 2 ** study.best_trial.params['hidden_dim']\n",
    "num_heads = study.best_trial.params['num_heads']\n",
    "learning_rate = 10 ** study.best_trial.params['learning_rate']\n",
    "num_epochs = int(study.best_trial.params['num_epochs'])\n",
    "batch_size = 2 ** study.best_trial.params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSFGCMzdZKPt"
   },
   "outputs": [],
   "source": [
    "train_dataloader = GraphDataLoader(train_dataset, batch_size=batch_size, drop_last=False)\n",
    "val_dataloader = GraphDataLoader(val_dataset, batch_size=batch_size, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(test_dataset, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XObk8oM6ZOry"
   },
   "outputs": [],
   "source": [
    "model = EdgeGATClassifier(input_dim, edge_dim, hidden_dim, num_classes, num_heads)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rteIwC-IZQyQ"
   },
   "outputs": [],
   "source": [
    "with tqdm(range(num_epochs), desc='Training Progress', unit='epoch') as epoch_progress:\n",
    "    for epoch in epoch_progress:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batched_graph, labels in train_dataloader:\n",
    "            preds = model(batched_graph)\n",
    "            loss = criterion(preds.float(), labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            avg_loss = total_loss / num_batches\n",
    "            epoch_progress.set_postfix({'Loss' : f\"{avg_loss:.4f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb2FYwxlZWAK"
   },
   "source": [
    "# 6. Validation\n",
    "- The purpose of validation is to find the optimal threshold to decide the labels for each predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuQRQlXLZaGL"
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        all_labels = []\n",
    "        for batched_graph, labels in dataloader:\n",
    "            pred = model(batched_graph)\n",
    "            all_pred.append(pred)\n",
    "            all_labels.append(labels.float())\n",
    "\n",
    "        all_pred = torch.sigmoid(torch.cat(all_pred))\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        precision, recall, threshold = precision_recall_curve(all_labels, all_pred)\n",
    "\n",
    "        f1 = precision * recall * 2 / (precision + recall)\n",
    "        f1 = np.nan_to_num(f1)\n",
    "        ix = np.argmax(f1)\n",
    "        opt_thr = threshold[ix]\n",
    "        print(f\"Optimal Threshold : {opt_thr}, F1 Score : {f1[ix]}\")\n",
    "\n",
    "        plt.plot(recall, precision, marker=',', label='EdgeGAT')\n",
    "        plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Optimal', linewidths=3)\n",
    "        plt.title('Precision - Recall Curve')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return opt_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TthyAoGMZdj_"
   },
   "outputs": [],
   "source": [
    "best_threshold = find_optimal_threshold(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TecknXxzZf1J"
   },
   "source": [
    "# 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ullfPePHZid5"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, threshold):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        all_labels = []\n",
    "        for batched_graph, labels in dataloader:\n",
    "            preds = model(batched_graph)\n",
    "            all_pred.append(preds)\n",
    "            all_labels.append(labels.float())\n",
    "\n",
    "        all_pred = torch.sigmoid(torch.cat(all_pred))\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        pred_labels = (all_pred >= threshold).long()\n",
    "\n",
    "        f1 = f1_score(all_labels, pred_labels)\n",
    "        accuracy = (pred_labels == all_labels).float().mean().item()\n",
    "        recall = recall_score(all_labels, pred_labels)\n",
    "\n",
    "        return f1, accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAYdsjejXfXn"
   },
   "outputs": [],
   "source": [
    "f1, accuracy, recall = evaluate(model, test_dataloader, best_threshold)\n",
    "print(f\"Accuracy : {accuracy:.4f}, Recall : {recall:.4f}, F1 : {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
